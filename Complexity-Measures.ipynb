{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing as t\n",
    "import numpy as np\n",
    "import itertools\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import LeaveOneOut\n",
    "from scipy.sparse.csgraph import minimum_spanning_tree\n",
    "from sklearn.metrics import accuracy_score\n",
    "from scipy.spatial import distance\n",
    "import matplotlib.pyplot as plt\n",
    "import math\n",
    "import random\n",
    "import gower"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "from sklearn.datasets import load_wine\n",
    "\n",
    "data_iris = load_iris()\n",
    "Y_iris = data_iris.target\n",
    "X_iris = data_iris.data\n",
    "\n",
    "data_wine = load_wine()\n",
    "Y_wine = data_wine.target\n",
    "X_wine = data_wine.data\n",
    "X_wine = X_wine[:,0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train_iris, X_test_iris, Y_train_iris, Y_test_iris = train_test_split(X_iris, Y_iris, test_size = 0.1)\n",
    "X_train_wine, X_test_wine, Y_train_wine, Y_test_wine = train_test_split(X_wine, Y_wine, test_size = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset train accuracy: 0.9925925925925926\n",
      "iris dataset test accuracy: 1.0\n",
      "-----------------------------------------------\n",
      "wine dataset train accuracy: 0.8625\n",
      "wine dataset train accuracy: 0.9444444444444444\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "model_iris = SVC(kernel = 'linear')\n",
    "model_iris.fit(X_train_iris, Y_train_iris)\n",
    "print(\"iris dataset train accuracy: \" + str(model_iris.score(X_train_iris, Y_train_iris)))\n",
    "print(\"iris dataset test accuracy: \" + str(model_iris.score(X_test_iris, Y_test_iris)))\n",
    "print(\"-----------------------------------------------\")\n",
    "model_wine = SVC(kernel = 'linear')\n",
    "model_wine.fit(X_train_wine, Y_train_wine)\n",
    "print(\"wine dataset train accuracy: \" + str(model_wine.score(X_train_wine, Y_train_wine)))\n",
    "print(\"wine dataset train accuracy: \" + str(model_wine.score(X_test_wine, Y_test_wine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_fx(X: np.ndarray, Y: np.ndarray) -> t.Dict[str, t.Any]:\n",
    "\n",
    "    prepcomp_vals = {}\n",
    "    \n",
    "    classes, class_freqs = np.unique(Y, return_counts=True)\n",
    "    cls_index = [np.equal(Y, i) for i in range(classes.shape[0])]\n",
    "\n",
    "    #cls_n_ex = np.array([np.sum(aux) for aux in cls_index])\n",
    "    cls_n_ex = list(class_freqs)\n",
    "    ovo_comb = list(itertools.combinations(range(classes.shape[0]), 2))\n",
    "    prepcomp_vals[\"ovo_comb\"] = ovo_comb\n",
    "    prepcomp_vals[\"cls_index\"] = cls_index\n",
    "    prepcomp_vals[\"cls_n_ex\"] = cls_n_ex\n",
    "    return prepcomp_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris dataset precompute\n",
    "precomp_fx_iris = precompute_fx(X_iris, Y_iris)\n",
    "cls_index_iris = precomp_fx_iris['cls_index'] #true-false\n",
    "cls_n_ex_iris = precomp_fx_iris['cls_n_ex']   # number of elements in each class\n",
    "ovo_comb_iris = precomp_fx_iris['ovo_comb']   # pairs\n",
    "\n",
    "# iris dataset precompute\n",
    "precomp_fx_wine = precompute_fx(X_wine, Y_wine)\n",
    "cls_index_wine = precomp_fx_wine['cls_index'] #true-false\n",
    "cls_n_ex_wine = precomp_fx_wine['cls_n_ex']   # number of elements in each class\n",
    "ovo_comb_wine = precomp_fx_wine['ovo_comb']   # pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris\n",
    "prepcomp_vals_iris = {}\n",
    "classes, class_freqs = np.unique(Y_iris, return_counts=True)\n",
    "cls_index = [np.equal(Y_iris, i) for i in range(classes.shape[0])]\n",
    "#cls_n_ex = np.array([np.sum(aux) for aux in cls_index])\n",
    "cls_n_ex_iris = list(class_freqs)\n",
    "ovo_comb_iris = list(itertools.combinations(range(classes.shape[0]), 2))\n",
    "prepcomp_vals_iris[\"ovo_comb\"] = ovo_comb_iris\n",
    "prepcomp_vals_iris[\"cls_index\"] = cls_index_iris\n",
    "prepcomp_vals_iris[\"cls_n_ex\"] = cls_n_ex_iris\n",
    "\n",
    "# wine\n",
    "prepcomp_vals_wine = {}\n",
    "classes, class_freqs = np.unique(Y_wine, return_counts=True)\n",
    "cls_index_wine = [np.equal(Y_wine, i) for i in range(classes.shape[0])]\n",
    "#cls_n_ex = np.array([np.sum(aux) for aux in cls_index])\n",
    "cls_n_ex_wine = list(class_freqs)\n",
    "ovo_comb_wine = list(itertools.combinations(range(classes.shape[0]), 2))\n",
    "prepcomp_vals_wine[\"ovo_comb\"] = ovo_comb_wine\n",
    "prepcomp_vals_wine[\"cls_index\"] = cls_index_wine\n",
    "prepcomp_vals_wine[\"cls_n_ex\"] = cls_n_ex_wine"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Feature-based Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Maximum Fisher’s Discriminant Ratio (F1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerator (X: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray, f: int) -> float:\n",
    "    summation = 0\n",
    "    for j in range(len(cls_n_ex)):\n",
    "        for k in range(len(cls_n_ex)): \n",
    "            summation += cls_n_ex[j]/sum(cls_n_ex) * cls_n_ex[k]/sum(cls_n_ex) * np.power((np.mean(X[cls_index[j], f])- np.mean(X[cls_index[k], f])), 2)\n",
    "    return summation\n",
    "# according to aquation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denominator (X: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray, f: int) -> float:\n",
    "    summation = 0\n",
    "    for j in range(len(cls_n_ex)):\n",
    "        summation += cls_n_ex[j]/sum(cls_n_ex) * np.power(np.std(X[cls_index[j], f]), 2)\n",
    "    return summation\n",
    "# according to aquation(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rfi (X: np.ndarray, cls_index, cls_n_ex) -> float:\n",
    "    return [numerator (X, cls_index, cls_n_ex, i)/denominator(X, cls_index, cls_n_ex, i) for i in range(np.shape(X)[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F1(X: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> float:\n",
    "    return 1/(1 + np.max(compute_rfi (X, cls_index, cls_n_ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset F1 score:  0.030199410224796608\n",
      "wine dataset F1 score:  0.24464900311262436\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset F1 score: \", str(ft_F1(X_iris, cls_index_iris, cls_n_ex_iris)))\n",
    "print(\"wine dataset F1 score: \", str(ft_F1(X_wine, cls_index_wine, cls_n_ex_wine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def numerator (X: np.ndarray, cls_index, cls_n_ex, i) -> float:\n",
    "    return np.sum([cls_n_ex[j]*np.power((np.mean(X[cls_index[j], i])-np.mean(X[:, i], axis=0)),2) for j in range (len(cls_index))])\n",
    "# according to aquation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def denominator (X: np.ndarray, cls_index, cls_n_ex, i) -> float:\n",
    "    return np.sum([np.sum(np.power(X[cls_index[j], i]-np.mean(X[cls_index[j], i], axis=0), 2)) for j in range(0, len(cls_n_ex))])\n",
    "# according to aquation(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_rfi (X: np.ndarray, cls_index, cls_n_ex) -> float:\n",
    "    return [numerator (X, cls_index, cls_n_ex, i)/denominator(X, cls_index, cls_n_ex, i) for i in range(np.shape(X)[1])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F1(X: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> float:\n",
    "    return 1/(1 + np.max(compute_rfi (X, cls_index, cls_n_ex)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset F1 score:  0.05862828094263205\n",
      "wine dataset F1 score:  0.39312127756629367\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset F1 score: \", str(ft_F1(X_iris, cls_index_iris, cls_n_ex_iris)))\n",
    "print(\"wine dataset F1 score: \", str(ft_F1(X_wine, cls_index_wine, cls_n_ex_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.2 The Directional-vector MaximumFisher's Discreminant Ratio (F1v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dVector(X: np.ndarray, y_class1: np.ndarray, y_class2: np.ndarray) -> float:\n",
    "    X_class1 = X[y_class1]; u_class1 = np.mean(X_class1, axis= 0)\n",
    "    X_class2 = X[y_class2]; u_class2 = np.mean(X_class2, axis= 0)\n",
    "    \n",
    "    W = ((np.shape(X_class1)[0]/ (np.shape(X_class1)[0] + np.shape(X_class2)[0]))* np.cov(X_class1.T)) \\\n",
    "     + (np.shape(X_class2)[0]/(np.shape(X_class1)[0] + (np.shape(X_class2)[0])) * np.cov(X_class2.T))\n",
    "    \n",
    "    d = np.dot(np.linalg.inv(W), (u_class1 - u_class2))\n",
    "    \n",
    "    B = np.dot((u_class1 - u_class2),((u_class1 - u_class2).T))\n",
    "    \n",
    "    return np.dot(np.dot(d.T, B), d)/ np.dot(np.dot(d.T, W), d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F1v(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray) ->float:\n",
    "    df_list = []\n",
    "    \n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        dF = dVector(X, y_class1, y_class2)\n",
    "        df_list.append(1/(1+dF))\n",
    "        \n",
    "    return np.mean(df_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset F1v score:  0.010007003139831785\n",
      "wine dataset F1v score:  0.015640180910802184\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset F1v score: \", str(ft_F1v(X_iris, ovo_comb_iris, cls_index_iris)))\n",
    "print(\"wine dataset F1v score: \", str(ft_F1v(X_wine, ovo_comb_wine, cls_index_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.3 Volume of Overlapping Region (F2)¶"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _minmax(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the minimum of the maximum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    max_cls = np.zeros((2, X.shape[1]))\n",
    "    max_cls[0, :] = np.max(X[class1], axis=0)\n",
    "    max_cls[1, :] = np.max(X[class2], axis=0)\n",
    "    aux = np.min(max_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _minmin(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the minimum of the minimum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    min_cls = np.zeros((2, X.shape[1]))\n",
    "    min_cls[0, :] = np.min(X[class1], axis=0)\n",
    "    min_cls[1, :] = np.min(X[class2], axis=0)\n",
    "    aux = np.min(min_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maxmin(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the maximum of the minimum values per class\n",
    "    for all features.\n",
    "    \"\"\"\n",
    "    min_cls = np.zeros((2, X.shape[1]))\n",
    "    min_cls[0, :] = np.min(X[class1], axis=0)\n",
    "    min_cls[1, :] = np.min(X[class2], axis=0)\n",
    "    aux = np.max(min_cls, axis=0)\n",
    "    \n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _maxmax(X: np.ndarray, class1: np.ndarray, class2: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the maximum of the maximum values per class\n",
    "    for all features. \n",
    "    \"\"\"\n",
    "    max_cls = np.zeros((2, X.shape[1]))\n",
    "    max_cls[0, :] = np.max(X[class1], axis=0)\n",
    "    max_cls[1, :] = np.max(X[class2], axis=0)\n",
    "    aux = np.max(max_cls, axis=0)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F2(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray) -> float:\n",
    "    f2_list = []\n",
    "    \n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        zero_ = np.zeros(np.shape(X)[1])\n",
    "        overlap_ = np.maximum(zero_, _minmax(X, y_class1, y_class2)-_maxmin(X, y_class1, y_class2))\n",
    "        range_ = _maxmax(X, y_class1, y_class2)-_minmin(X, y_class1, y_class2)\n",
    "        ratio = overlap_/range_\n",
    "        f2_list.append(np.prod(ratio))\n",
    "        \n",
    "    return np.mean(f2_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset F2 score:  0.0063817663817663794\n",
      "wine dataset F2 score:  0.0853552067458055\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset F2 score: \", str(ft_F2(X_iris, ovo_comb_iris, cls_index_iris)))\n",
    "print(\"wine dataset F2 score: \", str(ft_F2(X_wine, ovo_comb_wine, cls_index_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.4 Maximum Individual Feature Efficiency (F3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _compute_f3(X_: np.ndarray, minmax_: np.ndarray, maxmin_: np.ndarray) -> np.ndarray:\n",
    "    \"\"\" This function computes the F3 complexity measure given minmax and maxmin.\"\"\"\n",
    "\n",
    "    overlapped_region_by_feature = np.logical_and(X_ >= maxmin_, X_ <= minmax_)\n",
    "\n",
    "    n_fi = np.sum(overlapped_region_by_feature, axis=0)\n",
    "    idx_min = np.argmin(n_fi)\n",
    "\n",
    "    return idx_min, n_fi, overlapped_region_by_feature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F3(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> np.ndarray:\n",
    "    \n",
    "    f3 = []\n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        idx_min, n_fi, _ = _compute_f3(X, _minmax(X, cls_index[idx1], cls_index[idx2]),\n",
    "        _maxmin(X, cls_index[idx1], cls_index[idx2]))\n",
    "    f3.append(n_fi[idx_min] / (cls_n_ex[idx1] + cls_n_ex[idx2]))\n",
    "\n",
    "    return np.mean(f3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset F3 score:  0.37\n",
      "wine dataset F3 score:  1.0084033613445378\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset F3 score: \", str(ft_F3(X_iris, ovo_comb_iris, cls_index_iris, cls_n_ex_iris)))\n",
    "print(\"wine dataset F3 score: \", str(ft_F3(X_wine, ovo_comb_wine, cls_index_wine, cls_n_ex_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.5 Colective Feature Efficiency (F4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_F4(X: np.ndarray, ovo_comb: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> np.ndarray:\n",
    "\n",
    "    f4 = []\n",
    "    for idx1, idx2 in ovo_comb:\n",
    "        aux = 0\n",
    "\n",
    "        y_class1 = cls_index[idx1]\n",
    "        y_class2 = cls_index[idx2]\n",
    "        sub_set = np.logical_or(y_class1, y_class2)\n",
    "        y_class1 = y_class1[sub_set]\n",
    "        y_class2 = y_class2[sub_set]\n",
    "        X_ = X[sub_set, :]\n",
    "        # X_ = X[np.logical_or(y_class1, y_class2),:]\n",
    "    \n",
    "        while X_.shape[1] > 0 and X_.shape[0] > 0:\n",
    "            # True if the example is in the overlapping region\n",
    "            idx_min, _, overlapped_region_by_feature = _compute_f3(X_,_minmax(X_, y_class1, y_class2),_maxmin(X_, y_class1, y_class2))\n",
    "\n",
    "            # boolean that if True, this example is in the overlapping region\n",
    "            overlapped_region = overlapped_region_by_feature[:, idx_min]\n",
    "\n",
    "            # removing the non overlapped features\n",
    "            X_ = X_[overlapped_region, :]\n",
    "            y_class1 = y_class1[overlapped_region]\n",
    "            y_class2 = y_class2[overlapped_region]\n",
    "\n",
    "            if X_.shape[0] > 0:\n",
    "                aux = X_.shape[0]\n",
    "            else:\n",
    "                aux = 0\n",
    "            # removing the most efficient feature\n",
    "            X_ = np.delete(X_, idx_min, axis=1)\n",
    "\n",
    "        f4.append(aux/(cls_n_ex[idx1] + cls_n_ex[idx2]))\n",
    "        \n",
    "    return np.mean(f4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset F4 score:  0.043333333333333335\n",
      "wine dataset F4 score:  0.2864472891960523\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset F4 score: \", str(ft_F4(X_iris, ovo_comb_iris, cls_index_iris, cls_n_ex_iris)))\n",
    "print(\"wine dataset F4 score: \", str(ft_F4(X_wine, ovo_comb_wine, cls_index_wine, cls_n_ex_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Measures of Linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Sum of the Error Distance by Linear Programming (L1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_R1(model, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    y = model.decision_function(X)\n",
    "    w_norm = np.linalg.norm(model.coef_)\n",
    "    dist = y / w_norm\n",
    "    Y_predicted = model.predict(X)\n",
    "    distance = 0\n",
    "    for i in range(Y.shape[0]):\n",
    "        if(Y_predicted[i] != Y[i]):\n",
    "            distance += dist[i, 0] + dist[i, 1] + dist[i, 2]\n",
    "    SumErrorDist = distance/(Y.shape[0]*3)\n",
    "    L1 = SumErrorDist/(SumErrorDist + 1)\n",
    "    return L1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset L1 score:  0.0021275687081257675\n",
      "wine dataset L1 score:  0.02857311110212278\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset L1 score: \", str(ft_R1(model_iris, X_iris, Y_iris)))\n",
    "print(\"wine dataset L1 score: \", str(ft_R1(model_wine, X_wine, Y_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Error Rate of Linear Classifier (L2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_R2(model, X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    Y_predicted = model.predict(X)\n",
    "    counter = 0\n",
    "    for i in range(Y.shape[0]):\n",
    "        if(Y_predicted[i] != Y[i]):\n",
    "            counter += 1\n",
    "    L2 = counter / Y.shape[0]\n",
    "    return L2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset L2 score:  0.006666666666666667\n",
      "wine dataset L2 score:  0.12921348314606743\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset L2 score: \", str(ft_R2(model_iris, X_iris, Y_iris)))\n",
    "print(\"wine dataset L2 score: \", str(ft_R2(model_wine, X_wine, Y_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.3 Non-Linearity of a Linear Classifier (L3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_R3(model, X: np.ndarray, cls_index: np.ndarray, cls_n_ex: np.ndarray) -> float:\n",
    "    temp_x = []\n",
    "    temp_y = []\n",
    "    for i in range(len(cls_n_ex)):\n",
    "        for j in range(cls_n_ex[i]):\n",
    "            index = np.random.choice(cls_n_ex[i], 2, replace=False)\n",
    "            points = X[cls_index[i]][index]\n",
    "            rand = random.uniform(0, 1)\n",
    "            temp_x.append(((points[1] - points[0])*rand) + points[0])\n",
    "            temp_y.append(i)\n",
    "\n",
    "    temp_x = np.asarray(temp_x)\n",
    "    temp_y = np.asarray(temp_y)\n",
    "    R3 = ft_R2(model, temp_x, temp_y) \n",
    "    return R3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine dataset L3 score:  0.006666666666666667\n",
      "iris dataset L3 score:  0.06741573033707865\n"
     ]
    }
   ],
   "source": [
    "print(\"wine dataset L3 score: \", str(ft_R3(model_iris, X_iris, cls_index_iris, cls_n_ex_iris)))\n",
    "print(\"iris dataset L3 score: \", str(ft_R3(model_wine, X_wine, cls_index_wine, cls_n_ex_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Neighborhood Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Fraction of Borderline Points (N1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N1(X: np.ndarray, y: np.ndarray, metric: str = \"euclidean\") -> np.ndarray:\n",
    "    \n",
    "    # 0-1 scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X_ = scaler.transform(X)\n",
    "\n",
    "    # compute the distance matrix and the minimum spanning tree.\n",
    "    dist_m = np.triu(distance.cdist(X_, X_, metric), k=1)\n",
    "    mst = minimum_spanning_tree(dist_m)\n",
    "    \n",
    "#     plt.scatter(X[:, 0], X[:, 1])\n",
    "    \n",
    "#     for edge in mst:\n",
    "#         i, j = edge\n",
    "#         plt.plot([X[i, 0], X[j, 0]], [X[i, 1], X[j, 1]], c='r')\n",
    "#     plt.show()\n",
    "    \n",
    "    node_i, node_j = np.where(mst.toarray() > 0)\n",
    "\n",
    "    # which edges have nodes with different class\n",
    "    which_have_diff_cls = y[node_i] != y[node_j]\n",
    "\n",
    "    # number of different vertices connected\n",
    "    aux = np.unique(np.concatenate([node_i[which_have_diff_cls],node_j[which_have_diff_cls]])).shape[0]\n",
    "\n",
    "    return aux/X.shape[0]\n",
    "\n",
    "###############################show mst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = X_iris\n",
    "# y = Y_iris\n",
    "# metric = \"euclidean\"\n",
    "# scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "# X_ = scaler.transform(X)\n",
    "\n",
    "# # compute the distance matrix and the minimum spanning tree.\n",
    "# dist_m = np.triu(distance.cdist(X_, X_, metric), k=1)\n",
    "# mst = minimum_spanning_tree(dist_m)\n",
    "\n",
    "# plt.scatter(X[:, 0], X[:, 1])\n",
    "\n",
    "# for edge in mst:\n",
    "#     i, j = edge\n",
    "#     plt.plot([X[i, 0], X[j, 0]], [X[i, 1], X[j, 1]], c='r')\n",
    "# plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset N1 score:  0.1\n",
      "wine dataset N1 score:  0.29775280898876405\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset N1 score: \", str(ft_N1(X_iris, Y_iris)))\n",
    "print(\"wine dataset N1 score: \", str(ft_N1(X_wine, Y_wine)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mst.toarray().astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Ratio of Intra/Extra Class Nearest Neighbor Distance (N2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extra_nearest (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray, \n",
    "                   i: int, metric: str = \"euclidean\", n_neighbors=1) :\n",
    "    \" This function computes the distance from a point x_i to their nearest enemy\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    X_ = X[np.logical_not(cls_index[y[i]])]\n",
    "    y_ = y[np.logical_not(cls_index[y[i]])]\n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "    neigh.fit(X_, y_) \n",
    "    dist_enemy, pos_enemy = neigh.kneighbors([X[i, :]])\n",
    "    dist_enemy = np.reshape(dist_enemy, (n_neighbors,))\n",
    "    pos_enemy_ = np.reshape(pos_enemy, (n_neighbors,))\n",
    "    query = X_[pos_enemy_, :]\n",
    "    pos_enemy = np.where(np.all(X==query,axis=1))\n",
    "    pos_enemy = np.reshape(pos_enemy, (n_neighbors,))\n",
    "    return dist_enemy, pos_enemy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_nearest (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray,\n",
    "                                  i: int, metric: str = \"euclidean\", n_neighbors=1) :\n",
    "    \" This function computes the distance from a point x_i to their nearest neighboor from its own class\"\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    query = X[i, :]\n",
    "    label_query = y[i]\n",
    "    X_ = X[cls_index[label_query]]\n",
    "    y_ = y[cls_index[label_query]]\n",
    "    \n",
    "    pos_query = np.where(np.all(X_==query,axis=1))\n",
    "    X_ = np.delete(X_, pos_query, axis = 0)\n",
    "    y_ = np.delete(y_, pos_query, axis = 0) \n",
    "    \n",
    "    neigh = KNeighborsClassifier(n_neighbors=n_neighbors, metric=metric)\n",
    "    neigh.fit(X_, y_) \n",
    "    dist_neigh, pos_neigh = neigh.kneighbors([X[i, :]])\n",
    "    dist_neigh = np.reshape(dist_neigh, (n_neighbors,))\n",
    "    pos_neigh = np.reshape(pos_neigh, (n_neighbors,))\n",
    "    return dist_neigh, pos_neigh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def intra_extra(X: np.ndarray, y: np.ndarray, cls_index: np.ndarray) -> float:\n",
    "    intra = np.sum([intra_nearest (X, y, cls_index, i)[0] for i in range(np.shape(X)[0])])\n",
    "    extra = np.sum([extra_nearest (X, y, cls_index, i)[0] for i in range(np.shape(X)[0])])\n",
    "    return intra/extra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N2 (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray) -> float:\n",
    "    intra_extra_ = intra_extra(X, y, cls_index)\n",
    "    return intra_extra_/(1+intra_extra_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset N2 score:  0.1782317865334682\n",
      "wine dataset N2 score:  0.3765333377722287\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset N2 score: \", str(ft_N2(X_iris, Y_iris, cls_index_iris)))\n",
    "print(\"wine dataset N2 score: \", str(ft_N2(X_wine, Y_wine, cls_index_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Error Rate of the Nearest Neighbor Classifier (N3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N3 (X: np.ndarray, y: np.ndarray, metric: str = \"euclidean\") -> float:\n",
    "    \n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X_ = scaler.transform(X)\n",
    "    loo = LeaveOneOut()\n",
    "    loo.get_n_splits(X_, y)\n",
    "    \n",
    "    y_test_ = []\n",
    "    pred_y_ = []\n",
    "    for train_index, test_index in loo.split(X_):\n",
    "        X_train, X_test = X_[train_index], X_[test_index]\n",
    "        y_train, y_test = y[train_index], y[test_index]\n",
    "        model = KNeighborsClassifier(n_neighbors=1, metric=metric)\n",
    "        model.fit(X_train, y_train)\n",
    "        pred_y = model.predict(X_test)\n",
    "        y_test_.append(y_test)\n",
    "        pred_y_.append(pred_y)\n",
    "    \n",
    "    error = 1 - accuracy_score(y_test_, pred_y_)\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset N3 score:  0.046666666666666634\n",
      "wine dataset N3 score:  0.1853932584269663\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset N3 score: \", str(ft_N3(X_iris, Y_iris)))\n",
    "print(\"wine dataset N3 score: \", str(ft_N3(X_wine, Y_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.4 Non-Linearity of the Nearest Neighbor Classifier (N4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_N4(X: np.ndarray, y: np.ndarray, cls_index: np.ndarray, \n",
    "          metric: str = \"euclidean\", p=2, n_neighbors=1) -> np.ndarray:\n",
    "    interp_X = []\n",
    "    interp_y = []\n",
    "\n",
    "    # 0-1 scaler\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    \n",
    "    for idx in cls_index:\n",
    "        #creates a new dataset by interpolating pairs of training examples of the same class.\n",
    "        X_ = X[idx]\n",
    "\n",
    "        #two examples from the same class are chosen randomly and\n",
    "        #they are linearly interpolated (with random coefficients), producing a new example.\n",
    "        A = np.random.choice(X_.shape[0], X_.shape[0])\n",
    "        A = X_[A]\n",
    "        B = np.random.choice(X_.shape[0], X_.shape[0])\n",
    "        B = X_[B]\n",
    "        delta = np.random.ranf(X_.shape)\n",
    "        interp_X_ = A + ((B - A) * delta)\n",
    "        interp_y_ = y[idx]\n",
    "\n",
    "        interp_X.append(interp_X_)\n",
    "        interp_y.append(interp_y_)\n",
    "    \n",
    "    # join the datasets\n",
    "    X_test = np.concatenate(interp_X)\n",
    "    y_test = np.concatenate(interp_y)\n",
    "\n",
    "    knn = KNeighborsClassifier(n_neighbors=n_neighbors, p=p, metric=metric).fit(X, y)\n",
    "    y_pred = knn.predict(X_test)\n",
    "    error = 1 - accuracy_score(y_test, y_pred)\n",
    "\n",
    "    return error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset N4 score:  0.020000000000000018\n",
      "wine dataset N4 score:  0.1123595505617978\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset N4 score: \", str(ft_N4(X_iris, Y_iris, cls_index_iris)))\n",
    "print(\"wine dataset N4 score: \", str(ft_N4(X_wine, Y_wine, cls_index_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.5 Fraction of Hyperspheres Covering Data (T1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_matrix (X: np.ndarray):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    dist = distance.cdist(X, X, 'euclidean')\n",
    "    return dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def radios (D: np.ndarray, y: np.ndarray, X: np.ndarray, \n",
    "                        cls_index:np.ndarray, i: int) -> float:\n",
    "    d_i, x_j = extra_nearest(X, y, cls_index, i)\n",
    "    d_j, x_k = extra_nearest(X, y, cls_index, x_j[0])\n",
    "    if (i == x_k[0]):\n",
    "        return d_i/2\n",
    "    else :\n",
    "        d_t = radios (D, y, X, cls_index, x_j[0]) \n",
    "        var = d_i - d_t\n",
    "        return d_i - d_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hyperspher (D: np.ndarray, y: np.ndarray, X: np.ndarray, cls_index:np.ndarray) -> np.ndarray:\n",
    "    aux = [radios(D, y, X, cls_index, i) for i in range(X.shape[0])]\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T1(X: np.ndarray, Y: np.ndarray, cls_index: np.ndarray, eps: float) -> float:\n",
    "    D = distance_matrix(X)\n",
    "    hyper_list = hyperspher(D, Y, X, cls_index)\n",
    "    \n",
    "    for i in range(len(hyper_list)):\n",
    "        flag = True\n",
    "        while flag == True:\n",
    "            r = hyper_list[i] + eps\n",
    "            d, p = extra_nearest(X, Y, cls_index, i)\n",
    "            if d > hyper_list[i] + 2*eps:\n",
    "                hyper_list[i] = hyper_list[i] + eps\n",
    "            else:\n",
    "                flag = False\n",
    "    \n",
    "    checking = np.zeros(len(hyper_list))\n",
    "    for i in range(len(hyper_list)):\n",
    "        for j in range(len(hyper_list)):\n",
    "            if Y[i] == Y[j] and i != j:\n",
    "#                 print(i,j,D[i, j], hyper_list[i], hyper_list[j])\n",
    "                if D[i, j] + hyper_list[i] <= hyper_list[j]:\n",
    "                    checking[i] = 1\n",
    "                    break\n",
    "\n",
    "    counter = 0\n",
    "    backup = hyper_list\n",
    "    remnants = np.zeros(len(hyper_list))\n",
    "    while counter < 150:\n",
    "        if max(backup) == 0:\n",
    "            break\n",
    "        index = hyper_list.index(max(backup))\n",
    "        for i in range(len(hyper_list)):\n",
    "            if D[index, i] <= backup[index] and checking[i] != 1:\n",
    "                counter += 1\n",
    "                checking[i] = 1\n",
    "                remnants[index] = 1\n",
    "            backup[index] = 0\n",
    "    num = remnants.sum()\n",
    "    return num/len(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset T1 score:  0.98\n",
      "wine dataset T1 score:  0.8370786516853933\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset T1 score: \", str(ft_T1(X_iris, Y_iris, cls_index_iris, 0.001)))\n",
    "print(\"wine dataset T1 score: \", str(ft_T1(X_wine, Y_wine, cls_index_wine, 0.001)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.6 Local Set Average Cardinality (LSC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LS_i (X: np.ndarray, y: np.ndarray, i: int, cls_index, metric: str = \"euclidean\"):\n",
    "    dist_enemy, pos_enemy = extra_nearest(X, y, cls_index, i)\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1)).fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    dist_ = distance.cdist(X, [X[i, :]], metric=metric)\n",
    "    X_j = dist_[np.logical_and(dist_ < dist_enemy, dist_ != 0)]\n",
    "    return X_j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "def LSC (X: np.ndarray, y: np.ndarray, cls_index: np.ndarray) -> float:\n",
    "    n = np.shape(X)[0]\n",
    "    x = [np.shape(LS_i(X, y, i, cls_index)) for i in range(n)]\n",
    "    return 1 - np.sum(x)/n**2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset LSC score:  0.8243555555555555\n",
      "wine dataset LSC score:  0.9491225855321298\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset LSC score: \", str(LSC(X_iris, Y_iris, cls_index_iris)))\n",
    "print(\"wine dataset LSC score: \", str(LSC(X_wine, Y_wine, cls_index_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Network measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_adjucent_matrix(X, Y: np.ndarray) -> np.ndarray:\n",
    "    F = gower.gower_matrix(X)\n",
    "    connected = np.zeros((F.shape))\n",
    "    for i in range(F.shape[0]):\n",
    "        for j in range(F.shape[1]):\n",
    "            if F[i, j] <= 0.15 and i != j:\n",
    "                connected[i, j] = 1\n",
    "\n",
    "    for i in range(F.shape[0]):\n",
    "        for j in range(F.shape[1]):\n",
    "            if Y[i] != Y[j]:\n",
    "                connected[i, j] = 0\n",
    "    return connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(X, Y):\n",
    "    F = gower.gower_matrix(X)\n",
    "    G = gower.gower_matrix(X)\n",
    "    connected = np.zeros((F.shape))\n",
    "    for k in range(len(X)):\n",
    "        l = []\n",
    "        G[k].sort()\n",
    "        for i in range(1,int(0.15*X.shape[0])+1):\n",
    "            for j in range(len(X)):\n",
    "                if G[k,i] == F[k,j]:\n",
    "                    try:\n",
    "                        l.index(j)\n",
    "                    except:\n",
    "                        if Y[k] == Y[j]:\n",
    "    #                         print(k,j,F[k,j],Y[k], Y[j])\n",
    "                            connected[k, j] = 1\n",
    "                            l.append(j)\n",
    "                        break\n",
    "    return connected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8659060402684564"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "connected = test(X_iris, Y_iris)\n",
    "1-(connected.sum()/(X_iris.shape[0]*(X_iris.shape[0]-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Average density of the network (Density)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_Density(X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    F = gower.gower_matrix(X)\n",
    "    connected = np.zeros((F.shape))\n",
    "    for i in range(F.shape[0]):\n",
    "        for j in range(F.shape[1]):\n",
    "            if F[i, j] <= 0.15 and i != j:\n",
    "                connected[i, j] = 1\n",
    "\n",
    "    for i in range(F.shape[0]):\n",
    "        for j in range(F.shape[1]):\n",
    "            if Y[i] != Y[j]:\n",
    "                connected[i, j] = 0\n",
    "                \n",
    "    E = connected.sum()/2\n",
    "    aux = 1 - (2*E)/(F.shape[0]*(F.shape[0]-1))\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset Density score:  0.7641163310961969\n",
      "wine dataset Density score:  0.8316511140735098\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset Density score: \", str(ft_Density(X_iris, Y_iris)))\n",
    "print(\"wine dataset Density score: \", str(ft_Density(X_wine, Y_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.2 Clustering coefficient (ClsCoef)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_ClsCoef(X: np.ndarray, Y: np.ndarray) -> float:\n",
    "    connected = produce_adjucent_matrix(X, Y)\n",
    "#     connected = test(X, Y)\n",
    "    summation = 0\n",
    "    for i in range(connected.shape[0]):\n",
    "        neighbors = []\n",
    "        for k in range(connected[i, :].shape[0]):\n",
    "            if connected[i, k] == 1:\n",
    "                neighbors.append(k)\n",
    "        edge = 0\n",
    "        for m in range(len(neighbors)):\n",
    "            for n in range(m + 1, len(neighbors)):\n",
    "                if connected[m, n] == 1:\n",
    "                    edge = edge + 1\n",
    "        if len(neighbors) > 1:\n",
    "            summation = summation + (2*edge)/(len(neighbors)*(len(neighbors) - 1))\n",
    "    aux = 1 - summation/connected.shape[0]\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset ClsCoef score:  0.15443716931284934\n",
      "wine dataset ClsCoef score:  0.4088077102828107\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset ClsCoef score: \", str(ft_ClsCoef(X_iris, Y_iris)))\n",
    "print(\"wine dataset ClsCoef score: \", str(ft_ClsCoef(X_wine, Y_wine)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.3 Hub score (Hubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_Hubs2(X: np.ndarray, Y: np.ndarray, k: int) -> float:\n",
    "    connected = produce_adjucent_matrix(X, Y)\n",
    "    hubs = []\n",
    "    for i in range(connected.shape[0]):\n",
    "        hubs.append(sum(connected[i, :]))\n",
    "    hubs = hubs/sum(hubs)\n",
    "    for i in range(k):\n",
    "        for m in range(connected.shape[0]):\n",
    "            summation = 0\n",
    "            for n in range(connected.shape[1]):\n",
    "                if(connected[m, n] == 1):\n",
    "                    summation = summation + hubs[n]\n",
    "            hubs[m] = summation\n",
    "        hubs = hubs/sum(hubs)\n",
    "    return 1-sum(hubs)/len(hubs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_Hubs(X: np.ndarray, Y: np.ndarray, k: int) -> float:\n",
    "    connected = produce_adjucent_matrix(X, Y) \n",
    "#     connected = test(X, Y)\n",
    "    y0 = np.ones(connected.shape[0])\n",
    "    r = np.matmul(connected, y0)\n",
    "    r = r/np.sqrt(np.power(r, 2).sum())\n",
    "    for i in range(k):\n",
    "        r = np.matmul(connected, r)\n",
    "        r = r/np.sqrt(np.power(r, 2).sum())\n",
    "    return 1 - r.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset Hub score:  0.937333879580517\n",
      "wine dataset Hub score:  0.9474969504132738\n"
     ]
    }
   ],
   "source": [
    "k = 6\n",
    "print(\"iris dataset Hub score: \", ft_Hubs(X_iris, Y_iris, k))\n",
    "print(\"wine dataset Hub score: \", ft_Hubs(X_wine, Y_wine, k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 Dimensionality Measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def precompute_pca_tx(X: np.ndarray) -> t.Dict[str, t.Any]:\n",
    "    prepcomp_vals = {}\n",
    "\n",
    "    scaler = StandardScaler().fit(X)\n",
    "    X = scaler.transform(X)\n",
    "    pca = PCA(n_components=0.95)\n",
    "    pca.fit(X)\n",
    "\n",
    "    m_ = pca.explained_variance_ratio_.shape[0]\n",
    "    m = X.shape[1]\n",
    "    n = X.shape[0]\n",
    "\n",
    "    prepcomp_vals[\"m_\"] = m_\n",
    "    prepcomp_vals[\"m\"] = m\n",
    "    prepcomp_vals[\"n\"] = n\n",
    "\n",
    "    return prepcomp_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "precomp_pca = precompute_pca_tx(X_iris)\n",
    "iris_m = precomp_pca['m']\n",
    "iris_n = precomp_pca['n']\n",
    "iris_m_ = precomp_pca['m_']\n",
    "\n",
    "precomp_pca = precompute_pca_tx(X_wine)\n",
    "wine_m = precomp_pca['m']\n",
    "wine_n = precomp_pca['n']\n",
    "wine_m_ = precomp_pca['m_']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.1 Average number of features per points (T2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T2(m: int, n: int) -> float:\n",
    "    return m/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset T2 score:  0.02666666666666667\n",
      "wine dataset T2 score:  0.02247191011235955\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset T2 score: \", ft_T2(iris_m, iris_n))\n",
    "print(\"wine dataset T2 score: \", ft_T2(wine_m, wine_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.2 Average number of PCA dimensions per points (T3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T3(m_: int, n: int) -> float:\n",
    "    return m_/n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset T3 score:  0.013333333333333334\n",
      "wine dataset T3 score:  0.02247191011235955\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset T3 score: \", ft_T3(iris_m_, iris_n))\n",
    "print(\"wine dataset T3 score: \", ft_T3(wine_m_, wine_n))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5.3 Ratio of the PCA Dimension to the Original Dimension (T4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_T4(m: int, m_: int) -> float:\n",
    "    return m_/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset T4 score:  0.5\n",
      "wine dataset T4 score:  1.0\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset T4 score: \", ft_T4(iris_m, iris_m_))\n",
    "print(\"wine dataset T4 score: \", ft_T4(wine_m, wine_m_))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Class Imbalance Measures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.1 Entropy of class proportions (C1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_C1(cls_n_ex: np.ndarray) -> float:\n",
    "    nc = len(cls_n_ex)\n",
    "    n = sum(cls_n_ex)\n",
    "    summation = 0\n",
    "    for i in range(nc):\n",
    "        pi = cls_n_ex[i]/n\n",
    "        summation = summation + pi * math.log(pi)\n",
    "    aux = 1 + summation / math.log(nc)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset C1 score:  2.220446049250313e-16\n",
      "wine dataset C1 score:  0.011445206973490718\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset C1 score: \", ft_C1(cls_n_ex_iris))\n",
    "print(\"wine dataset C1 score: \", ft_C1(cls_n_ex_wine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.6.2 Imbalance ratio (C2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ft_C2(cls_n_ex: np.ndarray) -> float:\n",
    "    nc = len(cls_n_ex)\n",
    "    n = sum(cls_n_ex)\n",
    "    summation = 0\n",
    "    for i in range(nc):\n",
    "        summation = summation + cls_n_ex[i]/(n - cls_n_ex[i])\n",
    "    aux = ((nc - 1)/nc) * summation\n",
    "    aux = 1 - (1/aux)\n",
    "    return aux"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "iris dataset C2 score:  0.0\n",
      "wine dataset C2 score:  0.018697406258052607\n"
     ]
    }
   ],
   "source": [
    "print(\"iris dataset C2 score: \", ft_C2(cls_n_ex_iris))\n",
    "print(\"wine dataset C2 score: \", ft_C2(cls_n_ex_wine))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
